import streamlit as st
import google.generativeai as genai
import time

# --- CONFIGURATION DE L'API ---
# Note : La cl√© API est g√©r√©e automatiquement par l'environnement
API_KEY = "" 
genai.configure(api_key=API_KEY)

# Configuration du mod√®le pour un ton plus naturel et humain
generation_config = {
    "temperature": 0.9,
    "top_p": 0.95,
    "max_output_tokens": 1024,
}

SYSTEM_PROMPT = """
Tu es le M√©diateur Expert de NISFI, un conseiller matrimonial musulman sage et bienveillant.
TON BUT : Mener un entretien fluide pour apprendre √† conna√Ætre l'utilisateur.

R√àGLES D'OR :
1. NE JAMAIS se r√©p√©ter. Si tu n'as pas de nouvelle instruction, encourage l'utilisateur √† r√©pondre √† la question pos√©e.
2. TON HUMAIN : Pas de listes, pas de "En tant qu'IA". Parle comme un grand fr√®re.
3. √âCOUTE ACTIVE : Rebondis bri√®vement sur ce que l'utilisateur dit (ex: "MashaAllah, 30 ans est un bel √¢ge pour construire un foyer") avant de passer √† la suite.
4. ISLAM : Utilise des formules comme 'Barakallahou fik', 'Qu'Allah vous facilite' de fa√ßon naturelle.
5. CONCISION : 2-3 phrases maximum par r√©ponse.
"""

# Utilisation du mod√®le flash pour la rapidit√© et √©viter les blocages
model = genai.GenerativeModel(
    model_name="gemini-2.0-flash-thinking-exp-01-21",
    generation_config=generation_config,
    system_instruction=SYSTEM_PROMPT
)

# --- QUESTIONS ---
QUESTIONS = [
    {"id": "genre", "q": "Pour commencer cette belle √©tape, √™tes-vous un fr√®re ou une s≈ìur ?"},
    {"id": "prenom", "q": "C'est un plaisir de vous accueillir. Quel est votre pr√©nom ou votre Kunya ?"},
    {"id": "age", "q": "Et quel √¢ge avez-vous ?"},
    {"id": "ville", "q": "Dans quelle ville et pays r√©sidez-vous actuellement ?"},
    {"id": "situation", "q": "Quelle est votre situation matrimoniale actuelle ? (C√©libataire, divorc√©, veuf...)"},
    {"id": "enfants", "q": "Avez-vous des enfants ?"},
    {"id": "pratique", "q": "Comment d√©cririez-vous votre cheminement et votre niveau de pratique religieuse ?"},
    {"id": "vision", "q": "Quelle est votre vision du mariage et de la vie de famille en quelques mots ?"},
    {"id": "contact", "q": "Enfin, quelle est votre adresse e-mail pour le suivi ?"}
]

# --- INTERFACE ---
st.set_page_config(page_title="NISFI AI", page_icon="üåô")

st.markdown("""
    <style>
    .stApp { background-color: #f8f9fa; }
    .chat-bubble { padding: 15px; border-radius: 15px; margin-bottom: 10px; font-family: sans-serif; }
    .bot-msg { background-color: white; border: 1px solid #ddd; align-self: flex-start; }
    .user-msg { background-color: #1e7e34; color: white; align-self: flex-end; text-align: right; margin-left: 20%; }
    </style>
""", unsafe_allow_html=True)

# --- INITIALISATION ---
if "messages" not in st.session_state:
    st.session_state.messages = []
if "q_idx" not in st.session_state:
    st.session_state.q_idx = 0
if "gender" not in st.session_state:
    st.session_state.gender = None
if "chat_session" not in st.session_state:
    st.session_state.chat_session = model.start_chat(history=[])

# --- LOGIQUE ---
st.markdown("<h2 style='text-align: center; color: #1e7e34;'>üåô M√©diation NISFI</h2>", unsafe_allow_html=True)

# Affichage des messages
for msg in st.session_state.messages:
    cl = "user-msg" if msg["role"] == "user" else "bot-msg"
    st.markdown(f"<div class='chat-bubble {cl}'>{msg['content']}</div>", unsafe_allow_html=True)

# Premi√®re question automatique
if st.session_state.q_idx == 0 and not st.session_state.messages:
    welcome = "Assalamu Alaikum wa Rahmatullah. Je suis votre conseiller NISFI. " + QUESTIONS[0]["q"]
    st.session_state.messages.append({"role": "bot", "content": welcome})
    st.rerun()

# Entr√©e utilisateur
user_input = st.chat_input("Votre r√©ponse...")

if user_input:
    # Ajouter le message utilisateur √† l'√©cran
    st.session_state.messages.append({"role": "user", "content": user_input})
    
    # Identification du genre √† la premi√®re question
    if st.session_state.q_idx == 0:
        if any(x in user_input.lower() for x in ["soeur", "s≈ìur", "femme"]):
            st.session_state.gender = "soeur"
        else:
            st.session_state.gender = "frere"

    # Pr√©paration de la suite
    current_id = QUESTIONS[st.session_state.q_idx]["id"]
    st.session_state.q_idx += 1
    
    # Gestion de la fin ou de la question suivante
    if st.session_state.q_idx < len(QUESTIONS):
        next_q = QUESTIONS[st.session_state.q_idx]["q"]
        # Adaptation du genre
        if st.session_state.gender == "soeur":
            next_q = next_q.replace("mari√©", "mari√©e").replace("divorc√©", "divorc√©e")
            
        prompt = f"L'utilisateur (un {st.session_state.gender}) a r√©pondu '{user_input}' √† la question sur son {current_id}. Commente bri√®vement avec empathie et pose la question suivante : {next_q}"
    else:
        prompt = f"L'entretien est termin√©. L'utilisateur a fini de r√©pondre. Remercie-le chaleureusement et conclus avec une dou'a."

    # Appel API avec gestion d'erreur am√©lior√©e
    with st.spinner("R√©flexion de votre conseiller..."):
        try:
            response = st.session_state.chat_session.send_message(prompt)
            bot_text = response.text
        except Exception as e:
            # Fallback intelligent si l'API √©choue au lieu de boucler
            bot_text = "Barakallahou fik pour votre r√©ponse. Continuons notre √©change, c'est tr√®s enrichissant. "
            if st.session_state.q_idx < len(QUESTIONS):
                bot_text += QUESTIONS[st.session_state.q_idx]["q"]

        st.session_state.messages.append({"role": "bot", "content": bot_text})
    
    st.rerun()
